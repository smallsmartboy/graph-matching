\section{Related Work}

Recommendation systems have been studied extensively in the literature, %especially since the advent of the web. Most recommendation systems can be
broadly separated into two different streams: collaborative filtering systems and content-based recommender systems \cite{almazro2010survey}. Much attention has been focused on the former approach, where either users are clustered by considering the items they have consumed or items are clustered by considering the users that have bought them. Both item-to-item and user-to-user recommendation systems based on collaborative filtering have been adopted by many industry giants such as Twitter \cite{twitter-collab-filtering}, Amazon \cite{amazon-collab-filtering} and Google \cite{google-collab-filtering} and Netflix \cite{bellbellkor}.  \vs

Content based systems instead look at each item and its intrinsic properties. For example, Pandora has categorical information such as Artist, Genre, Year, Singer, Tempo etc. on each song it indexes. Similarly, Netflix has a lot of categorical data on movies and TV such as Cast, Director, Producers, Release Date, Budget, etc. This categorical data can then be used to recommend new songs that are similar to the songs that a user has liked before. Depending on user feedback, a recommender system can learn which of the categories are more or less important to a user and adjust its recommendations. \vs

A drawback of the first type of system is that is that they require multiple visits by many users so that a taste profile for each user, or a user profile for each item can be built.
Similarly, content-based systems also require significant user participation to train the underlying system. These conditions are possible to meet for large commerce or entertainment hubs,
%such as the companies mentioned above, 
but not very likely for most online retailers that specialize in a just a few areas, but have a long-tail~\cite{Anderson2006} of product offerings. \vs

Because of this constraint, in this paper we focus on a recommender system that typically uses many different algorithms that extract categorical data from item descriptions and uses this data to establish weak links between items (candidate recommendations). In the absence of other data that would enable us to choose among these many links, we consider every potential recommendation to be of equal value and focus on the objective of discovery, which has not been studied before. Using heuristics for building this graph is not only practical, but is theoretically sound as well\cite{sarkar2011theoretical}. In this way, our work differs from all the previous work on recommendation systems that emphasize on finding recommendations of high relevance and quality rather than on structural navigability of the realized link structure. However, while it's not included in this paper for brevity, some of our approaches can be extended to the more general case where different recommendations have different weights (See Theorem~\ref{wtd-thm}). \vs

On the graph algorithms side, our problem is related to the bipartite matching and more generally, the maximum $b$-matching problems. There has been considerable work done in this area.
 %when it comes to approximation algorithms. 
In particular, both the weighted matching and $b$-matching problems have exact polynomial time solutions ~\cite{Gabow1983}. Furthermore the matching problem admits a near linear time $(1-\epsilon)$-approximation algorithm~\cite{duan2010approximating}, while the weighted $b$-matching problem admits a $1/2$-approximation algorithm ~\cite{koufogiannakis2009distributed}. However, all such algorithms are based on combinatorial properties of matchings and $b$-matchings, and do not carry over to the more important version of our problem when $a > 1$.

Finally, our problem bears resemblance to some covering problems. For example, the maximum coverage problem asks for the maximum number of elements that can be covered by a fixed number of sets and has a greedy $(1-1/e)$-approximation ~\cite{nemhauser1978analysis}. However, as mentioned earlier, our formulation requires multiple coverage of elements. Furthermore note that the collection of sets that can be used in the redundant coverage are all possible subsets of $c$ out of the $d$ candidate links, and is expressed implicitly in our problem.  The currently known theoretical methods for maximum coverage heavily rely on the submodularity of the objective function, which our objective doesn't satisfy. Hence the line of recent work on approximation algorithms for submodular maximization does not apply to our problems. 