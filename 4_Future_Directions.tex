\vspace{-0.1in}
\section{Summary and Future Work}
We have presented a new class of structural recommendation problems
cast as computationally hard subgraph selection problems, and analyzed three algorithmic
strategies to solve these problems.
% because graph matching algorithms can be
%prohibitive to implement in real-world scenarios. 
The sampling method is most
efficient, the greedy approach trades off computational cost with
quality, and the partition method is effective for smaller problem
sizes. We have proved effective theoretical bounds on the quality
of these methods, and also substantiated them with experimental
validation both from simulated data and real data from
retail web sites. Our findings have been very useful in the
deployment of effective structural recommendations in web relevance
engines that drive many of the leading websites of popular retailers.

We believe that our work lends itself to promising future work in two directions.
The first is that through a better understanding of the underlying graph's topology,
more precise or complex models can be used. This would require an empirical validation of
the proposed graph model and the adaptation of our methods to different random graph models.
We have made some initial progress on this front, which can be found in the full version of the paper.

The second is that most of our algorithms aren't particularly suited for the weighted setting. While our sampling result carries over to the weighted regime as seen in Theorem \ref{wtd-thm}, our other algorithms don't, and even this result is weak compared to the unweighted result we presented in full. The problem presented by ignoring weights is that some really high value recommendations might be ignored by the randomness of the algorithm by chance. In practice, it's possible to mitigate this issue by hardcoding in the really desirable edges, and using seeding either the greedy or sampling algorithm with these edges. While this can work well in practice, it would be nonetheless be valuable to prove strong approximation guarantees in the weighted regime as well. \vs

\iffalse
Our sampling method and its analysis extends to more general
models of random graphs: in one version, we can consider
hierarchical models that take into account the product hierarchy
trees under which the pages in $L$ and $R$ are situated. A second
version considers a Cartesian product model where the pages in $L$
and $R$ are partitioned into closely related blocks and the graph
induced between every pair of left-right blocks follows a fixed
degree random model. A third variant models the potential flow of
customer traffic over each possible recommended edge from a left to
right page with nonnegative weights, and the resulting problem is
to find a subgraph where the number of right nodes with at least a
certain minimum amount of recommended traffic. Validating these
more general models by fitting real life data to them as well as
corroborating the performance of various methods in simulated and
real data for these models could yield an even better understanding
of our suggested algorithmic strategies for the
recommendation subgraph problem.\vs
\fi

{\bf Acknowledgments:} We thank Alan Frieze and Ashutosh Garg for helpful
discussions.

\vspace{-.05in} 